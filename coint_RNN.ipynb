{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation,GRU, SimpleRNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.layers import GRU, K, TimeDistributed\n",
    "from keras.models import model_from_json\n",
    "from copy import copy\n",
    "import warnings\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "T = 21*2\n",
    "i_dim = 20\n",
    "d_in = 0.2\n",
    "batch_size = 200\n",
    "N_range = 60*2\n",
    "profit_target_mul = 50\n",
    "stop_loss_mul = 25\n",
    "profit_target_vol_range_mul = 1.0\n",
    "stop_loss_vol_range_mul = 0.5\n",
    "t_hold = 30\n",
    "LONG = True\n",
    "return_T = 14\n",
    "dividends_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(X, y, T):\n",
    "    \n",
    "    pack = []\n",
    "    X_len = len(X)\n",
    "    for i in range(T, X_len+1):\n",
    "        pack.append([X[(i-T):i], y[i-1]])        \n",
    "    return pack\n",
    "\n",
    "\n",
    "def separate_train_val_test(arr, train_L, val_L):\n",
    "    \n",
    "    arr = np.array(arr)\n",
    "    return arr[:train_L], arr[train_L:(train_L+val_L)], arr[(train_L+val_L):]\n",
    "\n",
    "\n",
    "def load_dividends():\n",
    "    \n",
    "    global dividends_df\n",
    "    \n",
    "    sectors_info = pd.read_csv(\"sectors.csv\")\n",
    "    tickers = sectors_info[\"TICKER\"].values\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        \n",
    "        try:\n",
    "            div_df = pd.read_csv(os.path.join(os.path.abspath(\"div_data\"),\\\n",
    "                                                       ticker+\".csv\"))\n",
    "            div_df.index = pd.to_datetime(div_df[\"Ex-Date\"])\n",
    "            dividends_df[ticker] = div_df\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "def load_dataset(ticker1 = \"ADSK\", ticker2 = \"AMAT\", train_L_coef = 6, val_L_coef = 1):\n",
    "    \n",
    "    global profit_target_mul, dividends_df\n",
    "    \n",
    "    market_data = pd.read_csv(\"market_data_daily_resample_close.csv\", index_col = 0).ffill()\n",
    "    market_data.index = pd.to_datetime(market_data.index)\n",
    "    data = pd.DataFrame(index = market_data.index)\n",
    "    dates = market_data.index\n",
    "    S1 = market_data[ticker1]\n",
    "    S2 = market_data[ticker2]\n",
    "    S1_px = np.array(market_data[ticker1].values)\n",
    "    S2_px = np.array(market_data[ticker2].values)\n",
    "    S1_long_returns = 0.5 * (1.0 + (S1 - S1.shift(return_T)) / S1.shift(return_T))\n",
    "    S2_short_returns = 0.5 * (1.0 + (-S2 + S2.shift(return_T)) / S2.shift(return_T))\n",
    "    \n",
    "    train_L = round((len(S1_px) * train_L_coef) / (train_L_coef + val_L_coef))\n",
    "    val_L = round((len(S1_px) * val_L_coef) / (train_L_coef + val_L_coef))\n",
    "    \n",
    "    returns = S1_long_returns + S2_short_returns\n",
    "    log_returns = np.log1p(returns)\n",
    "    returns_series = pd.Series(data = returns)\n",
    "    returns_series_ewm = np.array(returns_series.ewm(span=return_T).std().values)\n",
    "    returns_series_ewm[0] = 0\n",
    "    \n",
    "    price_range_mean = returns_series_ewm\n",
    "    volatility_log_returns = [0] * len(returns)\n",
    "    volatility_returns = [0] * len(returns)\n",
    "    \n",
    "    for j in range(N_range-1, len(price_range_mean)):\n",
    "        volatility_log_returns = np.std(log_returns[j - N_range:j])+.0\n",
    "        volatility_returns = np.std(returns[j - N_range:j])+.0\n",
    "    \n",
    "    data[\"Returns\"] = returns\n",
    "    data['PriceRangeMean'] = price_range_mean\n",
    "    data['VolatilityLogReturns'] = volatility_log_returns\n",
    "    data['VolatilityReturns'] = volatility_returns\n",
    "    data['ClosePriceDiffS1'] = S1 - S1.shift(1)\n",
    "    data['ClosePriceDiffS2'] = S2 - S2.shift(1)\n",
    "    data['Ratio'] = (S1 / S2) > (S1 / S2).mean()\n",
    "    data['S1'] = S1\n",
    "    data['S2'] = S2\n",
    "    \n",
    "    stop_loss = np.array([0.0] * len(S1_px))\n",
    "    profit_target = np.array([0.0] * len(S1_px))\n",
    "    y_label = np.array([0] * len(S1_px))\n",
    "    price_range_mean = np.array(price_range_mean)\n",
    "    \n",
    "    for i in range(len(S1_px) - t_hold):\n",
    "        \n",
    "        profit_target_bips = 1.0 + 1.0 * profit_target_mul / 10000.0\n",
    "        stop_loss_bips = 1.0 - 1.0 * stop_loss_mul / 10000.0\n",
    "        profit_target_vol = 1.0 + price_range_mean[i] * profit_target_vol_range_mul\n",
    "        stop_loss_vol = 1.0 - price_range_mean[i] * stop_loss_vol_range_mul\n",
    "        \n",
    "        if i >= (N_range - 1):\n",
    "            profit_target[i] = min(profit_target_bips, profit_target_vol)\n",
    "            stop_loss[i] = max(stop_loss_bips, stop_loss_vol)\n",
    "        else:\n",
    "            profit_target[i] = profit_target_bips\n",
    "            stop_loss[i] = stop_loss_bips\n",
    "            \n",
    "        for j in range(1,t_hold + 1):\n",
    "            \n",
    "            PnL_long_cur = 0.5 * (S1_px[i + j] - S1_px[i]) / S1_px[i] +\\\n",
    "                0.5 * (-S2_px[i + j] + S2_px[i]) / S2_px[i] + 1.0\n",
    "                \n",
    "            if PnL_long_cur >= profit_target[i]:\n",
    "                y_label[i] = 1\n",
    "                break\n",
    "            elif PnL_long_cur <= stop_loss[i]:\n",
    "                y_label[i] = 0\n",
    "                break\n",
    "    \n",
    "    X = np.array(data.values) \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X)\n",
    "    X = sc.transform(X)\n",
    "    \n",
    "    X = X[(return_T+1):]\n",
    "    y_label = y_label[(return_T+1):]\n",
    "    stop_loss = stop_loss[(return_T+1):]\n",
    "    profit_target = profit_target[(return_T+1):]\n",
    "    S1_px = S1_px[(return_T+1):]\n",
    "    S2_px = S2_px[(return_T+1):]\n",
    "    price_range_mean = price_range_mean[(return_T+1):]\n",
    "    dates = dates[(return_T+1):]\n",
    "    \n",
    "    w_neu = len(y_label[y_label==0])/len(y_label)  \n",
    "    w_pos = len(y_label[y_label==1])/len(y_label)\n",
    "    class_weight = {0:1.0/w_neu,1:1.0/w_pos}\n",
    "\n",
    "    y_label = np.reshape(y_label, (len(y_label),1))\n",
    "    num_classes = 2\n",
    "    y_label = keras.utils.to_categorical(y_label, num_classes)\n",
    "    \n",
    "    X_train, X_val, X_test = separate_train_val_test(X, train_L, val_L)\n",
    "    y_label_train, y_label_val, y_label_test = separate_train_val_test(y_label, train_L, val_L)\n",
    "    stop_loss_train, stop_loss_val, stop_loss_test =\\\n",
    "            separate_train_val_test(stop_loss, train_L, val_L)\n",
    "    profit_target_train, profit_target_val, profit_target_test =\\\n",
    "            separate_train_val_test(profit_target, train_L, val_L)\n",
    "    dates_train, dates_val, dates_test = separate_train_val_test(dates, train_L, val_L)\n",
    "    s1_px_train, s1_px_val, s1_px_test = separate_train_val_test(S1_px, train_L, val_L)\n",
    "    s2_px_train, s2_px_val, s2_px_test = separate_train_val_test(S2_px, train_L, val_L)\n",
    "    price_range_mean_train, price_range_mean_val, price_range_mean_test =\\\n",
    "            separate_train_val_test(price_range_mean, train_L, val_L)\n",
    "\n",
    "    \n",
    "    \n",
    "    return X_train, X_val, X_test, y_label_train, y_label_val, y_label_test,\\\n",
    "            stop_loss_train, stop_loss_val, stop_loss_test,\\\n",
    "            profit_target_train, profit_target_val, profit_target_test,\\\n",
    "            dates_train, dates_val, dates_test,\\\n",
    "            s1_px_train, s1_px_val, s1_px_test,\\\n",
    "            s2_px_train, s2_px_val, s2_px_test,\\\n",
    "            price_range_mean_train, price_range_mean_val, price_range_mean_test, class_weight\n",
    "            \n",
    "            \n",
    "def treshold_plot(y_label_val_pred, y_label_val_true, width,\\\n",
    "                  layers, comm_coef = 10.0/10000.0):\n",
    "    \n",
    "    global dates_val, s1_px_val, s2_px_val, profit_target_val, stop_loss_val\n",
    "    \n",
    "    PnL_val, PnL_vecs_comm, commission_sum = calc_profit(y_label_val_pred, y_label_val_true,\\\n",
    "                    s1_px_val, s2_px_val, profit_target_val,\\\n",
    "                    stop_loss_val, comm_coef = 10.0/10000.0)\n",
    "    \n",
    "    \n",
    "    config_name = str(layers)+\",\"+str(width)+\",\"+str(profit_target_mul)+\",\"+str(stop_loss_mul)+\\\n",
    "                \",\"+str(profit_target_vol_range_mul)+\",\"+str(stop_loss_vol_range_mul)+\",2h,\"\n",
    "        \n",
    "    PnL_acc = np.sum(np.array(PnL_vecs_comm).T, axis = 1)\n",
    "    PnL_acc_comm = np.sum(np.array(PnL_vecs_comm).T, axis = 1)\n",
    "        \n",
    "        \n",
    "    for i in range(1,len(PnL_acc)):\n",
    "        PnL_acc[i] += PnL_acc[i-1]\n",
    "        if y_label_val_pred[i] == 1:\n",
    "            PnL_acc_comm[i] += PnL_acc_comm[i-1] - 2 * comm_coef\n",
    "        else:\n",
    "            PnL_acc_comm[i] += PnL_acc_comm[i-1]\n",
    "                        \n",
    "    PnL_acc_series = pd.Series(data=PnL_acc)\n",
    "    PnL_acc_series.index = dates_val\n",
    "    fig = PnL_acc_series.plot(title=config_name+\"no commission\",label=\"PnL,\"+config_name+\"no commision\",\\\n",
    "                        figsize = (12, 7), legend = True)\n",
    "    fig = fig.get_figure()\n",
    "        \n",
    "    PnL_acc_series = pd.Series(data=PnL_acc_comm)\n",
    "    PnL_acc_series.index = dates_val\n",
    "    fig = PnL_acc_series.plot(title=config_name+\"with commision\",label=\"PnL,\"+config_name+\"with commision\",\\\n",
    "                    figsize = (12, 7), legend = True)\n",
    "    fig = fig.get_figure()\n",
    "        \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "                         \n",
    "                         \n",
    "def calc_profit(dates_val, y_label_pred, y_label_true, s1_px, s2_px, profit_target,\\\n",
    "                    stop_loss, comm_coef = 10.0/10000.0, ticker1 = \"ADSK\", ticker2 = \"AMAT\"):\n",
    "    \n",
    "    global dividends_df\n",
    "    \n",
    "    PnL = .0\n",
    "    y_label_pred = np.array(y_label_pred).argmax(axis = 1)\n",
    "    y_label_true = np.array(y_label_true).argmax(axis = 1)\n",
    "    PnL_vecs_comm = []\n",
    "    commission_sum =.0\n",
    "    \n",
    "    for i in range(T - 1, len(y_label_true) - t_hold - 1):\n",
    "        PnL_vec_comm = np.zeros(len(s1_px))\n",
    "        \n",
    "        if y_label_pred[i] == 1:\n",
    "            \n",
    "            trig_sl = 0\n",
    "            commission_sum += -2*comm_coef\n",
    "            \n",
    "            for j in range(1, t_hold + 1):\n",
    "                                \n",
    "                PnL_priv = 0.5 * (s1_px[i + j - 1] - s1_px[i]) / s1_px[i] +\\\n",
    "                    0.5 * (-s2_px[i + j - 1] + s2_px[i]) / s2_px[i] + 1.0\n",
    "                    \n",
    "                PnL_cur = 0.5 * (s1_px[i + j] - s1_px[i]) / s1_px[i] +\\\n",
    "                    0.5 * (-s2_px[i + j] + s2_px[i]) / s2_px[i] + 1.0\n",
    "                        \n",
    "    \n",
    "                if PnL_cur <= stop_loss[i]:\n",
    "                    \n",
    "                    PnL += (stop_loss[i] - PnL_priv)\n",
    "                    PnL_vec_comm[i+j] = (stop_loss[i] - PnL_priv)\n",
    "                    trig_sl = 1\n",
    "                    break\n",
    "                \n",
    "                elif PnL_cur >= profit_target[i]:\n",
    "                    \n",
    "                    PnL += (profit_target[i] - PnL_priv)\n",
    "                    PnL_vec_comm[i+j] = (profit_target[i] - PnL_priv)\n",
    "                    trig_sl = 1\n",
    "                    break\n",
    "                    \n",
    "                PnL_dividends = .0\n",
    "                date = dates_val[i + j]\n",
    "                \n",
    "                if ticker1 in dividends_df.keys():\n",
    "                    \n",
    "                    if date in dividends_df[ticker1].index:\n",
    "                        \n",
    "                        if dividends_df[ticker1].loc[date][\"Dividend Type\"] == \"Regular Cash\":\n",
    "\n",
    "                            PnL_dividends += dividends_df[ticker1].loc[date][\"Dividend Amount\"] / s1_px[i]\n",
    "                            \n",
    "                if ticker2 in dividends_df.keys():\n",
    "                    \n",
    "                    if date in dividends_df[ticker2].index:\n",
    "                        \n",
    "                        if dividends_df[ticker2].loc[date][\"Dividend Type\"] == \"Regular Cash\":\n",
    "\n",
    "                            PnL_dividends -= dividends_df[ticker2].loc[date][\"Dividend Amount\"] / s2_px[i]\n",
    "                            \n",
    "                \n",
    "                PnL_vec_comm[i+j] = PnL_cur - PnL_priv + PnL_dividends\n",
    "                PnL += PnL_cur - PnL_priv + PnL_dividends\n",
    "                    \n",
    "            if trig_sl == 0:\n",
    "                \n",
    "                PnL += 0.5 * (s1_px[i + t_hold + 1] - s1_px[i + t_hold]) / s1_px[i] +\\\n",
    "                    0.5 * (-s2_px[i + t_hold + 1] + s2_px[i + t_hold]) / s2_px[i]\n",
    "                    \n",
    "                PnL_vec_comm[i+j] = 0.5 * (s1_px[i + t_hold + 1] - s1_px[i + t_hold]) / s1_px[i] +\\\n",
    "                    0.5 * (-s2_px[i + t_hold + 1] + s2_px[i + t_hold]) / s2_px[i] \n",
    "                \n",
    "        PnL_vecs_comm.append(PnL_vec_comm)\n",
    "        \n",
    "    return PnL, PnL_vecs_comm, commission_sum\n",
    "\n",
    "    \n",
    "def schedule(ind, lr):\n",
    "    \n",
    "    return lr * (0.98)**ind\n",
    "\n",
    "\n",
    "def save_model(model, name = \"short,noSL\"):\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(\"model\"+name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"model\"+name+\".h5\")\n",
    "    \n",
    "    \n",
    "def load_model(name):\n",
    "    \n",
    "    json_file = open('model'+name+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"model\"+name+\".h5\")\n",
    "    return model\n",
    "\n",
    "\n",
    "class My_Callback(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global X_val, y_label_val_true, dates_val, s1_px_val,\\\n",
    "            s2_px_val, profit_target_val, stop_loss_val\n",
    "              \n",
    "        y_label_val_pred = self.model.predict(x=X_val)        \n",
    "        PnL_val, PnL_comm_matrix, commission_sum = calc_profit(dates_val, y_label_val_pred, y_label_val_true,\\\n",
    "                                                               s1_px_val, s2_px_val, profit_target_val,\\\n",
    "                    stop_loss_val, comm_coef = 10.0/10000.0, ticker1 = \"ADSK\", ticker2 = \"AMAT\")\n",
    "        \n",
    "        print(\"Return with transaction costs: \", np.round(PnL_val+commission_sum, 2), '\\n',\\\n",
    "              \"Return without transaction costs: \", np.round(PnL_val, 2))\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 64, 0)\n",
      "Train on 2492 samples, validate on 366 samples\n",
      "Epoch 1/20\n",
      "2492/2492 [==============================] - 9s 4ms/step - loss: 1.4029 - acc: 0.4583 - val_loss: 0.7275 - val_acc: 0.3279\n",
      "Return with transaction costs:  -0.53 \n",
      " Return without transaction costs:  0.06\n",
      "Epoch 2/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3866 - acc: 0.5056 - val_loss: 0.7088 - val_acc: 0.3361\n",
      "Return with transaction costs:  -0.53 \n",
      " Return without transaction costs:  0.05\n",
      "Epoch 3/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3867 - acc: 0.5024 - val_loss: 0.7067 - val_acc: 0.3579\n",
      "Return with transaction costs:  -0.49 \n",
      " Return without transaction costs:  0.07\n",
      "Epoch 4/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3874 - acc: 0.5076 - val_loss: 0.6909 - val_acc: 0.5191\n",
      "Return with transaction costs:  -0.36 \n",
      " Return without transaction costs:  0.05\n",
      "Epoch 5/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3883 - acc: 0.5120 - val_loss: 0.6840 - val_acc: 0.6311\n",
      "Return with transaction costs:  -0.18 \n",
      " Return without transaction costs:  0.09\n",
      "Epoch 6/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3837 - acc: 0.5189 - val_loss: 0.6773 - val_acc: 0.6585\n",
      "Return with transaction costs:  -0.02 \n",
      " Return without transaction costs:  0.07\n",
      "Epoch 7/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3874 - acc: 0.5116 - val_loss: 0.6773 - val_acc: 0.6393\n",
      "Return with transaction costs:  -0.04 \n",
      " Return without transaction costs:  0.07\n",
      "Epoch 8/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3835 - acc: 0.5313 - val_loss: 0.6775 - val_acc: 0.6366\n",
      "Return with transaction costs:  -0.07 \n",
      " Return without transaction costs:  0.08\n",
      "Epoch 9/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3831 - acc: 0.5269 - val_loss: 0.6781 - val_acc: 0.6175\n",
      "Return with transaction costs:  -0.12 \n",
      " Return without transaction costs:  0.07\n",
      "Epoch 10/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3786 - acc: 0.5397 - val_loss: 0.6769 - val_acc: 0.6284\n",
      "Return with transaction costs:  -0.1 \n",
      " Return without transaction costs:  0.07\n",
      "Epoch 11/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3821 - acc: 0.5257 - val_loss: 0.6769 - val_acc: 0.6257\n",
      "Return with transaction costs:  -0.14 \n",
      " Return without transaction costs:  0.05\n",
      "Epoch 12/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3775 - acc: 0.5457 - val_loss: 0.6765 - val_acc: 0.6230\n",
      "Return with transaction costs:  -0.11 \n",
      " Return without transaction costs:  0.07\n",
      "Epoch 13/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3829 - acc: 0.5301 - val_loss: 0.6774 - val_acc: 0.6148\n",
      "Return with transaction costs:  -0.16 \n",
      " Return without transaction costs:  0.05\n",
      "Epoch 14/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3780 - acc: 0.5341 - val_loss: 0.6762 - val_acc: 0.6202\n",
      "Return with transaction costs:  -0.13 \n",
      " Return without transaction costs:  0.06\n",
      "Epoch 15/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3836 - acc: 0.5257 - val_loss: 0.6767 - val_acc: 0.6230\n",
      "Return with transaction costs:  -0.14 \n",
      " Return without transaction costs:  0.06\n",
      "Epoch 16/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3828 - acc: 0.5389 - val_loss: 0.6770 - val_acc: 0.6202\n",
      "Return with transaction costs:  -0.17 \n",
      " Return without transaction costs:  0.05\n",
      "Epoch 17/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3790 - acc: 0.5413 - val_loss: 0.6767 - val_acc: 0.6257\n",
      "Return with transaction costs:  -0.15 \n",
      " Return without transaction costs:  0.06\n",
      "Epoch 18/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3848 - acc: 0.5217 - val_loss: 0.6768 - val_acc: 0.6148\n",
      "Return with transaction costs:  -0.17 \n",
      " Return without transaction costs:  0.04\n",
      "Epoch 19/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3888 - acc: 0.5209 - val_loss: 0.6770 - val_acc: 0.6038\n",
      "Return with transaction costs:  -0.19 \n",
      " Return without transaction costs:  0.04\n",
      "Epoch 20/20\n",
      "2492/2492 [==============================] - 4s 2ms/step - loss: 1.3817 - acc: 0.5321 - val_loss: 0.6772 - val_acc: 0.6066\n",
      "Return with transaction costs:  -0.18 \n",
      " Return without transaction costs:  0.05\n",
      "366/366 [==============================] - 0s 443us/step\n",
      "3 64 0 -0.17700000000000135\n"
     ]
    }
   ],
   "source": [
    "load_dividends()\n",
    "\n",
    "epochs = 20\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1=0.9,\\\n",
    "                                    beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True, clipvalue = 0.5)\n",
    "\n",
    "X_train_arr, X_val_arr, X_test_arr, y_label_train_arr, y_label_val_arr, y_label_test_arr,\\\n",
    "            stop_loss_train, stop_loss_val, stop_loss_test,\\\n",
    "            profit_target_train, profit_target_val, profit_target_test,\\\n",
    "            dates_train, dates_val, dates_test,\\\n",
    "            s1_px_train, s1_px_val, s1_px_test,\\\n",
    "            s2_px_train, s2_px_val, s2_px_test,\\\n",
    "            price_range_mean_train, price_range_mean_val, price_range_mean_test, class_weight = load_dataset()\n",
    "            \n",
    "\n",
    "train_set = make_dataset(X_train_arr, y_label_train_arr, T)\n",
    "val_set = make_dataset(X_val_arr, y_label_val_arr, T)\n",
    "test_set = make_dataset(X_test_arr, y_label_test_arr, T)\n",
    "\n",
    "X_train = np.array([x[0] for x in train_set])\n",
    "y_label_train_true = np.array([x[1] for x in train_set])\n",
    "X_val = np.array([x[0] for x in val_set])\n",
    "y_label_val_true = np.array([x[1] for x in val_set])\n",
    "X_test = np.array([x[0] for x in test_set])\n",
    "y_label_test_true = np.array([x[1] for x in test_set])\n",
    "             \n",
    "i_dim = np.shape(X_train)[2]\n",
    "\n",
    "results = []\n",
    "profit_target_mul_arr = [50]\n",
    "stop_loss_mul_arr = [25]\n",
    "profit_target_vol_range_mul_arr = np.array([1.8])\n",
    "stop_loss_vol_range_mul_arr = np.array([0.9])\n",
    "\n",
    "for layers in range(3, 4):\n",
    "    for width_exp in range(6, 7):\n",
    "        for profit_loss_config in range(1):\n",
    "            \n",
    "                profit_target_mul = profit_target_mul_arr[profit_loss_config]\n",
    "                stop_loss_mul = stop_loss_mul_arr[profit_loss_config]\n",
    "                profit_target_vol_range_mul = profit_target_vol_range_mul_arr[profit_loss_config]\n",
    "                stop_loss_vol_range_mul = stop_loss_vol_range_mul_arr[profit_loss_config]\n",
    "                \n",
    "                width_layer = 2**(width_exp)\n",
    "                model = Sequential()\n",
    "                model.add(TimeDistributed(Dense(64), input_shape=(T, i_dim)))\n",
    "                \n",
    "                print((layers, width_layer, profit_loss_config))\n",
    "                \n",
    "                X_train_arr, X_val_arr, X_test_arr, y_label_train_arr, y_label_val_arr, y_label_test_arr,\\\n",
    "                stop_loss_train, stop_loss_val, stop_loss_test,\\\n",
    "                profit_target_train, profit_target_val, profit_target_test,\\\n",
    "                dates_train, dates_val, dates_test,\\\n",
    "                s1_px_train, s1_px_val, s1_px_test,\\\n",
    "                s2_px_train, s2_px_val, s2_px_test,\\\n",
    "                price_range_mean_train, price_range_mean_val,\\\n",
    "                    price_range_mean_test, class_weight = load_dataset()\n",
    "                    \n",
    "                train_set = make_dataset(X_train_arr, y_label_train_arr, T)\n",
    "                val_set = make_dataset(X_val_arr, y_label_val_arr, T)\n",
    "                test_set = make_dataset(X_test_arr, y_label_test_arr, T)\n",
    "                \n",
    "                X_train = np.array([x[0] for x in train_set])\n",
    "                y_label_train_true = np.array([x[1] for x in train_set])\n",
    "                X_val = np.array([x[0] for x in val_set])\n",
    "                y_label_val_true = np.array([x[1] for x in val_set])\n",
    "                X_test = np.array([x[0] for x in test_set])\n",
    "                y_label_test_true = np.array([x[1] for x in test_set])\n",
    "                \n",
    "                \n",
    "                if layers > 1:\n",
    "                    model.add(GRU(width_layer,return_sequences=True, dropout=d_in)) \n",
    "                else:\n",
    "                    model.add(GRU(width_layer,return_sequences=False, dropout=d_in))\n",
    "                    \n",
    "                for w in range(1,layers-1):\n",
    "                    model.add(GRU(width_layer,return_sequences=True, dropout=d_in))  #75 hidden neurons\n",
    "                        \n",
    "                if layers > 1:\n",
    "                    model.add(GRU(width_layer,return_sequences=False, dropout=d_in))\n",
    "                \n",
    "                model.add(Dense(64, activation='relu'))\n",
    "                early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\\\n",
    "                                              patience=10, verbose=0, mode='auto',\\\n",
    "                                              baseline=None)\n",
    "                lr_sched = keras.callbacks.LearningRateScheduler(schedule, verbose=0)\n",
    "                reduce_lr_plateau = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\\\n",
    "                                                                      patience=3, verbose=0,\\\n",
    "                                                                      mode='auto', min_delta=0.0001,\\\n",
    "                                                                      cooldown=0, min_lr=0.00001)\n",
    "                model.add(Dense(2, activation='softmax'))\n",
    "                model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
    "                model.fit(x=X_train, y=y_label_train_true,\\\n",
    "                          validation_data = (X_val,y_label_val_true), epochs=epochs,\\\n",
    "                                 shuffle = False, callbacks=[early_stopping,lr_sched,My_Callback()],\\\n",
    "                                 class_weight = class_weight)\n",
    "                    \n",
    "                \n",
    "                eval_val = model.evaluate(x=X_val, y=y_label_val_true)\n",
    "                y_label_val_pred = model.predict(x=X_val)\n",
    "                \n",
    "                PnL_val, PnL_comm_matrix, commission_sum = calc_profit(dates_val, y_label_val_pred, y_label_val_true,\\\n",
    "                                                               s1_px_val, s2_px_val, profit_target_val,\\\n",
    "                    stop_loss_val, comm_coef = 10.0/10000.0, ticker1 = \"ADSK\", ticker2 = \"AMAT\")\n",
    "\n",
    "                print(layers, width_layer, profit_loss_config, PnL_val + commission_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
